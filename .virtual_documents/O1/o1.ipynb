











import sys,os
sys.path.append(os.path.expanduser('./libitmal'))

from libitmal import utils as itmalutils
print(dir(itmalutils))
print(itmalutils.__file__)





from libitmal import utils as itmalutils

itmalutils.TestAll()








import malutils

malutils.HelloWorld()
malutils.Greeter("Pokemon!")





import importlib
importlib.reload(malutils)









class MyClass:
    def myFun(self):
        self.myvar = "Public function"
        print(f"This is a message inside the class, myvar={self.myvar}.")

    #private function
    def __myfun(self):
        self.myvar = "Private"
        print(f"This is a private message inside the class, myvar={self.myvar}.")

    def callToPrivate(self):
        print(f"Calling private function, myvar={self.myvar}.")
        self.__myfun()
        print("Done with private function")

    def myFun2(): # this wont work!
        print("No self")


instance = MyClass()

instance.myFun()
try:
    instance.__myfun()
except:
    print("Exception: can't call private function")

instance.callToPrivate()
try:
    instance.myFun2()
except:
    print("Exception: no self class method!")








class MyCtorClass:
    def __init__(self,x):
        self.x = x
        print(f"Constructor called with x={x}")

    def GetX(self):
        return self.x

ctorInstance = MyCtorClass(42)
num = ctorInstance.GetX()
print(f"numn from instance = {num}")






class MyToStringClass:
    def __init__(self,x):
        self.x = x

    def __str__(self):
        return f"MyToStringClass (x={self.x})"

strClass = MyToStringClass(420)
print(strClass)





import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model
import os

def prepare_country_stats(oecd_bli, gdp_per_capita):
    oecd_bli = oecd_bli[oecd_bli["INEQUALITY"]=="TOT"]
    oecd_bli = oecd_bli.pivot(index="Country", columns="Indicator", values="Value")
    gdp_per_capita.rename(columns={"2015": "GDP per capita"}, inplace=True)
    gdp_per_capita.set_index("Country", inplace=True)
    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,
                                  left_index=True, right_index=True)
    full_country_stats.sort_values(by="GDP per capita", inplace=True)
    remove_indices = [0, 1, 6, 8, 33, 34, 35]
    keep_indices = list(set(range(36)) - set(remove_indices))
    return full_country_stats[["GDP per capita", 'Life satisfaction']].iloc[keep_indices]

datapath = os.path.join("./datasets", "lifesat", "")

# Load the data
oecd_bli = pd.read_csv(datapath + "oecd_bli_2015.csv", thousands=',')
gdp_per_capita = pd.read_csv(datapath + "gdp_per_capita.csv",thousands=',',delimiter='\t',
                             encoding='latin1', na_values="n/a")

# Prepare the data
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

# Visualize the data
#country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
#plt.show()

# Select a linear model
model = sklearn.linear_model.LinearRegression()
# Train the model
model.fit(X, y)

print("OK")









# skæring ved x-aksen
theta_0 = model.intercept_
# koefficienten
theta_1 = model.coef_[0]
print(f"h(x) = {theta_0[0]:.4f} + {theta_1[0]}x")

u = np.sum((y - model.predict(X))**2)
v = np.sum((y - np.mean(y))**2)

R2 = 1 - u/v
R2_skl = model.score(X, y)
print(f"R2 = {R2}")
print(f"R2_skl = {R2_skl}")








# Prepare the data
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

print("X.shape=",X.shape)
print("y.shape=",y.shape)

# Visualize the data
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
plt.show()

# Select and train a model
k = 3
knn = sklearn.neighbors.KNeighborsRegressor(k)
knn.fit(X, y)

# Plot knn
m = np.linspace(0, 60000, 1000)
M = np.empty([m.shape[0], 1])
M[:, 0] = m

y_pred_lin = model.predict(M)  # Linear regression predictions
y_pred_knn = knn.predict(M)

# Create the plot
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction', figsize=(8, 6))
plt.axis([0, 60000, 0, 10])

# Plot both model predictions
plt.plot(m, y_pred_lin, "r-", label="Linear Regression", linewidth=2)
plt.plot(m, y_pred_knn, "b--", label=f"KNN (k={k})", linewidth=2)

# Add labels and legend
plt.xlabel("GDP per capita (USD)")
plt.ylabel("Life satisfaction")
plt.legend()
plt.title("Comparison of Linear Regression vs KNN Regression")
plt.show()

# Print model performance
print(f"Linear Regression Score (R²): {model.score(X, y):.3f}")
print(f"KNN Score (R²): {knn.score(X, y):.3f}")

# Make prediction for Cyprus
X_cyprus = [[22587]]
lin_pred = model.predict(X_cyprus)
knn_pred = knn.predict(X_cyprus)

print(f"\nPredictions for Cyprus (GDP = 22587 USD):")
print(f"Linear Regression: {lin_pred[0][0]:.2f}")
print(f"KNN (k={k}): {knn_pred[0]}")

knn_score = knn.score(X, y)
print(f"KNN score              : {knn_score}")
print(f"Linear Regression score: {R2_skl}")









country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction', figsize=(5,3))
plt.axis([0, 60000, 0, 10])

# create an test matrix M, with the same dimensionality as X, and in the range [0;60000]
# and a step size of your choice
m=np.linspace(0, 60000, 1000)
M=np.empty([m.shape[0],1])
M[:,0]=m

# from this test M data, predict the y values via the lin.reg. and k-nearest models
y_pred_lin = model.predict(M)
y_pred_knn = knn.predict(M)   # ASSUMING the variable name 'knn' of your KNeighborsRegressor

# use plt.plot to plot x-y into the sample_data plot..
plt.plot(m, y_pred_lin, "r", label="Linear Regression")
plt.plot(m, y_pred_knn, "b", label="KNN (k=3)")
knn_score3 = knn.score(X, y)

knn = sklearn.neighbors.KNeighborsRegressor(1)
knn.fit(X, y)
knn_score1 = knn.score(X, y)
y_pred_knn1 = knn.predict(M)
plt.plot(m, y_pred_knn1, "y--", label="KNN (k=1)")

knn = sklearn.neighbors.KNeighborsRegressor(2)
knn.fit(X, y)
knn_score2 = knn.score(X, y)
y_pred_knn2 = knn.predict(M)
plt.plot(m, y_pred_knn2, "g--", label="KNN (k=2)")

knn = sklearn.neighbors.KNeighborsRegressor(10)
knn.fit(X, y)
knn_score10 = knn.score(X, y)
y_pred_knn10 = knn.predict(M)
plt.plot(m, y_pred_knn10, "k--", label="KNN (k=10)")

plt.legend()
plt.show()

#scores
print(f"KNN score (k=1)   : {knn_score1}")
print(f"KNN score (k=2)   : {knn_score2}")
print(f"KNN score (k=3)   : {knn_score3}")
print(f"KNN score (k=10)  : {knn_score10}")
print(f"Linear Regression score: {R2_skl}")





from sklearn.neural_network import MLPRegressor

# Setup MLPRegressor
mlp = MLPRegressor( hidden_layer_sizes=(10,), solver='adam', activation='relu', tol=1E-5, max_iter=100000, verbose=True)
mlp.fit(X, y.ravel())

# lets make a MLP regressor prediction and redo the plots
y_pred_mlp = mlp.predict(M)

mlp_score = mlp.score(X, y)

plt.plot(m, y_pred_lin, "r", label="Linear Regression")
plt.plot(m, y_pred_knn, "b", label="KNN (k=3)")
plt.plot(m, y_pred_mlp, "k", label="MLP (h=10)")

plt.legend()
plt.show()

y_nn_pred = mlp.predict(X_cyprus)
print(f"Predictions for Cyprus (GDP = 22587 USD): {y_nn_pred[0]}")

# Scores
print(f"KNN score (k=3)   : {knn_score3}")
print(f"Linear Regression score: {R2_skl}")
print(f"MLP score         : {mlp_score}")















import numpy as np

y_true = np.array([1,2,3,4]) # NOTE: you'll need this later
X = np.array([[1,2,3],[4,2,1],[3,8,5],[-9,-1,0]])

print("X_true = \n", X)








import math

def L1(x): 
    if x.ndim != 1:
        raise ValueError("expected x to be of ndim=1, got ndim=",X.ndim)    
    sum = 0
    for i in x: 
        if i > 0:
            sum += i
        else:
            sum += -i
    return sum 


def L2(x):
    if x.ndim != 1:
        raise ValueError("expected x to be of ndim=1, got ndim=",X.ndim)    
    sum = 0
    for i in x:     
        sum += i**2
    sum = sum**0.5
    return sum

def L2Dot(x):
    assert x.ndim == 1 and isinstance(x, np.ndarray)
    return x.dot(x)**0.5

# TEST vectors: here I test your implementation...calling your L1() and L2() functions
tx=np.array([1, 2, 3, -1])
ty=np.array([3,-1, 4,  1])

expected_d1=8.0
expected_d2=4.242640687119285

d1=L1(tx-ty)
d2=L2(tx-ty)

print(f"tx-ty={tx-ty}, d1-expected_d1={d1-expected_d1}, d2-expected_d2={d2-expected_d2}")

eps=1E-9
assert math.fabs(d1-expected_d1)<eps, "L1 dist seems to be wrong"
assert math.fabs(d2-expected_d2)<eps, "L2 dist seems to be wrong"

print("OK(part-1)")

d2dot=L2Dot(tx-ty)
print("d2dot-expected_d2=",d2dot-expected_d2)
assert math.fabs(d2dot-expected_d2)<eps, "L2Ddot dist seem to be wrong"
print("OK(part-2)")





def RMSE(y_pred, y_true):
    assert len(y_pred) == len(y_true) and y_pred.ndim == 1 and y_true.ndim == 1
    err_vec = y_pred - y_true
    l2 = L2(err_vec)
    return l2 / len(err_vec)**0.5

# Dummy h function:
def h(X):
    if X.ndim!=2:
        raise ValueError("excpeted X to be of ndim=2, got ndim=",X.ndim)
    if X.shape[0]==0 or X.shape[1]==0:
        raise ValueError("X got zero data along the 0/1 axis, cannot continue")
    return X[:,0]

# Calls your RMSE() function:
r=RMSE(h(X), y_true)

eps=1E-9
expected=6.57647321898295
print(f"RMSE={r}, diff={r-expected}")
assert math.fabs(r-expected)<eps, "your RMSE dist seems to be wrong"

print("OK")





def MAE(y_pred, y_true):
    assert len(y_pred) == len(y_true) and y_pred.ndim == 1 and y_true.ndim == 1
    err_vec = y_pred - y_true
    return L1(err_vec) / len(err_vec)


# Calls your MAE function:
r=MAE(h(X), y_true)

# TEST vector:
expected=3.75
print(f"MAE={r}, diff={r-expected}")
assert math.fabs(r-expected)<eps, "MAE dist seems to be wrong"

print("OK")














import matplotlib.pyplot as plt
import matplotlib
from sklearn.datasets import fetch_openml

def MNIIST_GetDataSet():
    X, y = fetch_openml('mnist_784', return_X_y=True, cache=True, as_frame=False)
    return X, y

X, y = MNIIST_GetDataSet()
print(f"Shape of X: {X.shape}")


def MNIST_PlotDigit(data):
    image = data.reshape(28, 28)
    plt.imshow(image, cmap = matplotlib.cm.binary)
    plt.axis("off")

MNIST_PlotDigit(X[0])
plt.show()








from sklearn.linear_model import SGDClassifier

X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]

y_train_5 = (y_train == '5')
y_test_5 = (y_test == '5')

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train_5)

sgd_predict_5 = sgd_clf.predict(X_test)





true_positives = []
false_positives = []
false_negatives = []
for i in range(len(y_test_5)):
    if y_test_5[i] == True and sgd_predict_5[i] == True:
        true_positives.append(i)
    elif y_test_5[i] == False and sgd_predict_5[i] == True:
        false_positives.append(i)
    elif y_test_5[i] == True and sgd_predict_5[i] == False:
        false_negatives.append(i)
print(f"Number of true positives : {len(true_positives)}")
print(f"Number of false positives: {len(false_positives)}")
print(f"Number of false negatives: {len(false_negatives)}")





# Plotting some true positives:
def PlotMultiple(amount, indicies, X):
    fig, axes = plt.subplots(1, amount, figsize=(12, 4))
    for i in range(amount):
        plt.subplot(1, amount, i + 1)
        MNIST_PlotDigit(X[indicies[i]])

    plt.tight_layout()
    plt.show()

PlotMultiple(10, true_positives, X_test)


# Plotting some false positives
PlotMultiple(10, false_positives, X_test)


# Plotting some false negatives
PlotMultiple(10, false_negatives, X_test)








from sklearn.metrics import accuracy_score
from sklearn.base import BaseEstimator, ClassifierMixin
import numpy as np

class DummyClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, strategy):
        self.strategy = strategy

    def fit(self, X, y=None):
        # Actually do nothing
        return self

    def predict(self, X):
        n_samples = X.shape[0]
        return np.full(n_samples, self.strategy)

    def score(self, X, y):
        y_pred = self.predict(X)
        return accuracy_score(y, y_pred)





dummy = DummyClassifier(False)
dummy.fit(X_train, y_train_5)

dummy_pred = dummy.predict(X_test)
dummy_score = dummy.score(X_test, y_test_5)
print(f"dummy_score: {dummy_score}")

















import math

def UnpackPerfMetrics(y_true, y_pred):
    assert y_true.shape == y_pred.shape and y_true.shape[0] > 0
    TP, TN, FP, FN = 0, 0, 0, 0
    for i, _ in enumerate(y_pred):
        if y_true[i] == True and y_pred[i] == True:
            TP += 1
        elif y_true[i] == False and y_pred[i] == False:
            TN += 1
        elif y_true[i] == True and y_pred[i] == False:
            FN += 1
        else:
            FP += 1
    return TP, TN, FP, FN

def MyAccuracy(y_true, y_pred):
    TP, TN, FP, FN = UnpackPerfMetrics(y_true, y_pred)
    accuracy = (TP + TN) / y_true.shape[0]
    return accuracy

from sklearn.metrics import accuracy_score

def TestAccuracy(y_true, y_pred):
    a0=MyAccuracy(y_true, y_pred)
    a1=accuracy_score(y_true, y_pred)

    print(f"MyAccuracy     = {a0}")
    print(f"accuracy_score = {a1}")

    eps = 1E-9
    if math.fabs(a0 - a1) > eps:
        raise ValueError("Difference in MyAccuracy and accuracy_score too big!")

TestAccuracy(y_test_5, sgd_predict_5)
TestAccuracy(y_test_5, dummy_pred)









from sklearn.metrics import precision_score, recall_score, f1_score
def MyPrecision(y_true, y_pred):
    TP, TN, FP, FN = UnpackPerfMetrics(y_true, y_pred)
    if TP + FP == 0: return 0.0
    return TP / (TP + FP)

def MyRecall(y_true, y_pred):
    TP, TN, FP, FN = UnpackPerfMetrics(y_true, y_pred)
    if TP + FN == 0: return 0.0
    return TP / (TP + FN)

def MyF1Score(y_true, y_pred):
    precision = MyPrecision(y_true, y_pred)
    recall = MyRecall(y_true, y_pred)
    if precision == 0 or recall == 0: return 0.0
    return 2 / (1/precision + 1/recall)

def TestMetrics(y_true, y_pred):
    p0 = MyPrecision(y_true, y_pred)
    p1 = precision_score(y_true, y_pred)

    r0 = MyRecall(y_true, y_pred)
    r1 = recall_score(y_true, y_pred)

    f1_0 = MyF1Score(y_true, y_pred)
    f1_1 = f1_score(y_true, y_pred)

    eps = 1E-9

    print(f"MyPrecision     = {p0}")
    print(f"precision_score = {p1}")
    if math.fabs(p0 - p1) > eps:
        raise ValueError("Difference in MyPrecision and precision_score too big!")

    print(f"MyRecall        = {r0}")
    print(f"recall_score    = {r1}")
    if math.fabs(r0 - r1) > eps:
        raise ValueError("Difference in MyRecall and recall_score too big!")

    print(f"MyF1Score       = {f1_0}")
    print(f"f1_score        = {f1_1}")
    if math.fabs(f1_0 - f1_1) > eps:
        raise ValueError("Difference in MyF1Score and f1_score too big!")

print("SGD Performance Metrics")
TestMetrics(y_test_5, sgd_predict_5)
print("=============")
print("Dummy Performance Metrics")
TestMetrics(y_test_5, dummy_pred)






from sklearn.metrics import confusion_matrix

M_dummy = confusion_matrix(y_test_5, dummy_pred)
M_SGD = confusion_matrix(y_test_5, sgd_predict_5)

print("M_dummy:\n", M_dummy)
print("M_SGD:\n", M_SGD)

M_dummy_swapped = confusion_matrix(dummy_pred, y_test_5)
M_SGD_swapped = confusion_matrix(sgd_predict_5, y_test_5)

print("M_dummy_swapped:\n", M_dummy_swapped)
print("M_SGD_swapped:\n", M_SGD_swapped)











from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

ConfusionMatrixDisplay.from_predictions(y_test_5, sgd_predict_5, cmap="Grays")
plt.title("SGD Confusion Matrix")
plt.figure()
ConfusionMatrixDisplay.from_predictions(y_test_5, dummy_pred, cmap="Grays")
plt.title("DummyClassifier Confusion Matrix")
plt.show()





from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.model_selection import cross_val_predict
from sklearn.preprocessing import StandardScaler

# had to reduce size due to taking too long to create plots

scaler = StandardScaler()

X_train_small = X_train[:10000]
y_train_small = y_train[:10000]

X_train_scaled_small = scaler.fit_transform(X_train_small.astype(np.float64))

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled_small, y_train_small, cv=3, n_jobs=4)
ConfusionMatrixDisplay.from_predictions(y_train_small, y_train_pred)
plt.show()

ConfusionMatrixDisplay.from_predictions(y_train_small, y_train_pred,
normalize="true", values_format=".0%")
plt.show()

sample_weight = (y_train_pred != y_train_small)
ConfusionMatrixDisplay.from_predictions(y_train_small, y_train_pred, sample_weight=sample_weight, normalize="true", values_format=".0%")
plt.show()









